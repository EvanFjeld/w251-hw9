{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cace261f",
   "metadata": {
    "id": "cace261f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim\n",
    "\n",
    "import torch.utils.data\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "#import torch.nn.functional as F\n",
    "#from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "\n",
    "import torch.distributed as dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61812400",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPU=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "363e2b75",
   "metadata": {
    "id": "363e2b75"
   },
   "outputs": [],
   "source": [
    "SEED=1\n",
    "\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "cudnn.deterministic = True\n",
    "\n",
    "scaler = GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f5c1cfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d479743",
   "metadata": {
    "id": "0d479743"
   },
   "outputs": [],
   "source": [
    "START_EPOCH = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97b1a0aa",
   "metadata": {
    "id": "97b1a0aa",
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "ARCH = 'resnet18'\n",
    "EPOCHS = 2\n",
    "LR = 0.1\n",
    "MOMENTUM = 0.9\n",
    "WEIGHT_DECAY = 5e-4\n",
    "PRINT_FREQ = 50\n",
    "TRAIN_BATCH=1024\n",
    "VAL_BATCH=1024\n",
    "WORKERS=1\n",
    "RANK=0\n",
    "\n",
    "TRAINDIR=\"/data/train\"\n",
    "VALDIR=\"/data/val\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86c3188",
   "metadata": {
    "id": "e86c3188"
   },
   "source": [
    "### Check if cuda is available here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63a0499b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "63a0499b",
    "outputId": "4a90cd73-a4b2-42ea-fb9a-e3afb36f2063"
   },
   "outputs": [],
   "source": [
    "# check if cuda is available in this cell\n",
    "# if it is not available, you should not go forward!\n",
    "if not torch.cuda.is_available():\n",
    "    print(\"GPU not detected...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e5ddf20",
   "metadata": {
    "id": "1e5ddf20"
   },
   "outputs": [],
   "source": [
    "# set your active device to your GPU in this cell\n",
    "device = torch.device(\"cuda:0\")\n",
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cdd6e12",
   "metadata": {
    "id": "7cdd6e12"
   },
   "source": [
    "### Fill in the heart of the train section below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70dbd4c4",
   "metadata": {
    "id": "70dbd4c4"
   },
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, epoch):\n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    data_time = AverageMeter('Data', ':6.3f')\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "    top5 = AverageMeter('Acc@5', ':6.2f')\n",
    "    progress = ProgressMeter(\n",
    "        len(train_loader),\n",
    "        [batch_time, data_time, losses, top1, top5],\n",
    "        prefix=\"Epoch: [{}]\".format(epoch))\n",
    "\n",
    "    ######################\n",
    "    # switch model to train mode here\n",
    "    model.train()\n",
    "    ################\n",
    "    \n",
    "    end = time.time()\n",
    "    for i, (images, target) in enumerate(train_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        #####################\n",
    "        # send the images to cuda device\n",
    "        #images = pad_sequence(images, batch_first=True, padding_value=0)\n",
    "        images = images.to(device)\n",
    "        # send the target to cuda device\n",
    "        target = target.to(device)\n",
    "\n",
    "        # compute output\n",
    "        with autocast():\n",
    "            output = model(images)\n",
    "\n",
    "        # compute loss\n",
    "        with autocast():\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "        losses.update(loss.item(), images.size(0))\n",
    "        top1.update(acc1[0], images.size(0))\n",
    "        top5.update(acc5[0], images.size(0))\n",
    "\n",
    "\n",
    "        #### zero out gradients in the optimier\n",
    "        optimizer.zero_grad()\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        ## backprop!\n",
    "        #loss.backward()\n",
    "\n",
    "        # update the weights!\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if i % PRINT_FREQ == 0:\n",
    "            progress.display(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb3b62e",
   "metadata": {
    "id": "deb3b62e"
   },
   "source": [
    "#### Fill in the validate section below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3f276cc",
   "metadata": {
    "id": "a3f276cc"
   },
   "outputs": [],
   "source": [
    "def validate(val_loader, model, criterion):\n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "    top5 = AverageMeter('Acc@5', ':6.2f')\n",
    "    progress = ProgressMeter(\n",
    "        len(val_loader),\n",
    "        [batch_time, losses, top1, top5],\n",
    "        prefix='Test: ')\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    with torch.cuda.amp.autocast():\n",
    "        end = time.time()\n",
    "        for i, (images, target) in enumerate(val_loader):\n",
    "            \n",
    "            # pad the input images to the same length\n",
    "            #images = pad_sequence(images, batch_first=True)\n",
    "            \n",
    "            ### send the images and target to cuda\n",
    "            images = images.cuda()\n",
    "            target = target.cuda()\n",
    "\n",
    "            # compute output\n",
    "            output = model(images)\n",
    "\n",
    "            # compute loss\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "            losses.update(loss.item(), images.size(0))\n",
    "            top1.update(acc1[0], images.size(0))\n",
    "            top5.update(acc5[0], images.size(0))\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            if i % PRINT_FREQ == 0:\n",
    "                progress.display(i)\n",
    "\n",
    "        # TODO: this should also be done with the ProgressMeter\n",
    "        print(' * Acc@1 {top1.avg:.3f} Acc@5 {top5.avg:.3f}'\n",
    "              .format(top1=top1, top5=top5))\n",
    "\n",
    "    return top1.avg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe49226",
   "metadata": {
    "id": "fbe49226"
   },
   "source": [
    "### Save the checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff8a4159",
   "metadata": {
    "id": "ff8a4159"
   },
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\n",
    "    # save the model state!\n",
    "    torch.save(state, filename)\n",
    "    \n",
    "    if is_best:\n",
    "        shutil.copyfile(filename, 'model_best.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1cd7ea3a",
   "metadata": {
    "id": "1cd7ea3a"
   },
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self, name, fmt=':f'):\n",
    "        self.name = name\n",
    "        self.fmt = fmt\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def __str__(self):\n",
    "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
    "        return fmtstr.format(**self.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e1da87ab",
   "metadata": {
    "id": "e1da87ab"
   },
   "outputs": [],
   "source": [
    "class ProgressMeter(object):\n",
    "    def __init__(self, num_batches, meters, prefix=\"\"):\n",
    "        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n",
    "        self.meters = meters\n",
    "        self.prefix = prefix\n",
    "\n",
    "    def display(self, batch):\n",
    "        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n",
    "        entries += [str(meter) for meter in self.meters]\n",
    "        print('\\t'.join(entries))\n",
    "\n",
    "    def _get_batch_fmtstr(self, num_batches):\n",
    "        num_digits = len(str(num_batches // 1))\n",
    "        fmt = '{:' + str(num_digits) + 'd}'\n",
    "        return '[' + fmt + '/' + fmt.format(num_batches) + ']'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "00211030",
   "metadata": {
    "id": "00211030"
   },
   "outputs": [],
   "source": [
    "# if we are adjusting the LR manually use this\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
    "    lr = LR * (0.1 ** (epoch // 30))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "da2c1382",
   "metadata": {
    "id": "da2c1382"
   },
   "outputs": [],
   "source": [
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5c29e7a1",
   "metadata": {
    "id": "5c29e7a1"
   },
   "outputs": [],
   "source": [
    "imagenet_mean_RGB = [0.47889522, 0.47227842, 0.43047404]\n",
    "imagenet_std_RGB = [0.24205776, 0.23828046, 0.25874835]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e1a61c02",
   "metadata": {
    "id": "e1a61c02"
   },
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=imagenet_mean_RGB, std=imagenet_std_RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "47dd3e49",
   "metadata": {
    "id": "47dd3e49"
   },
   "outputs": [],
   "source": [
    "IMG_SIZE = 224\n",
    "INPUT_SIZE = 256\n",
    "NUM_CLASSES = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4387cb",
   "metadata": {
    "id": "de4387cb"
   },
   "source": [
    "### Initialize the model using the architecture you selected above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b1abcc33",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 158,
     "referenced_widgets": [
      "3ed3d41696734302b0a8c2bb5a9026cc",
      "4205c04d3e5c4244b144861a9263a322",
      "11839112304746f9a7fd76784958faa4",
      "ae70f8cd257b47cc9af26e1dc7c1ec38",
      "620dae24fc9e4be0b245c019bfb7f4c5",
      "dee11a91c86e4ca1a05b7cb62af41fee",
      "48c5147a2da546af988e4dea6703653a",
      "e952a4ef79f2406082f01c1ef44be20e",
      "e62345a5fe3244e3ad50cee5ff01ae93",
      "2a86b108d37548eba7e5042a00f6d63a",
      "2a592d63a5b24791ad351b5c911fac65"
     ]
    },
    "id": "b1abcc33",
    "outputId": "a35b9eae-97fa-4402-b2bb-c7330adaf1ba"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# select the model\n",
    "model = models.__dict__[ARCH](pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db1bb69",
   "metadata": {
    "id": "2db1bb69"
   },
   "source": [
    "### Send the model to the cuda device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7d23ccb4",
   "metadata": {
    "id": "7d23ccb4"
   },
   "outputs": [],
   "source": [
    "model.cuda(GPU)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a8eb8d",
   "metadata": {
    "id": "47a8eb8d"
   },
   "source": [
    "### Instantiate the loss to cross entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a49ae3c9",
   "metadata": {
    "id": "a49ae3c9"
   },
   "outputs": [],
   "source": [
    "# use the cross-entropy loss\n",
    "criterion = nn.CrossEntropyLoss().cuda(GPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a49045a",
   "metadata": {
    "id": "8a49045a"
   },
   "source": [
    "### Instantiate the optimizer to SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aa3a04dd",
   "metadata": {
    "id": "aa3a04dd"
   },
   "outputs": [],
   "source": [
    "# use SGD .. use the momentum and weight decay vars\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LR, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93ef11d",
   "metadata": {
    "id": "f93ef11d"
   },
   "source": [
    "#### Create the learning rate scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a0e1727a",
   "metadata": {
    "id": "a0e1727a"
   },
   "outputs": [],
   "source": [
    "# use CosineAnnealingLR\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS, eta_min=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2fe08caa",
   "metadata": {
    "id": "2fe08caa"
   },
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize(INPUT_SIZE),\n",
    "    transforms.CenterCrop(IMG_SIZE),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(imagenet_mean_RGB, imagenet_std_RGB),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236528e1",
   "metadata": {
    "id": "236528e1"
   },
   "source": [
    "### Create the train dataset object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7c29f6b1",
   "metadata": {
    "id": "7c29f6b1"
   },
   "outputs": [],
   "source": [
    "train_dataset = datasets.ImageFolder(root=TRAINDIR, \n",
    "                                     transform=transform_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "63dfe3c0",
   "metadata": {
    "id": "63dfe3c0"
   },
   "outputs": [],
   "source": [
    "transform_val = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(imagenet_mean_RGB, imagenet_std_RGB),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ca6c39",
   "metadata": {
    "id": "38ca6c39"
   },
   "source": [
    "### Create the val dataset object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "42d58f82",
   "metadata": {
    "id": "42d58f82"
   },
   "outputs": [],
   "source": [
    "# use torchvision.datasets.CIFAR10\n",
    "# val_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_val)\n",
    "val_dataset = datasets.ImageFolder(root=VALDIR, transform=transform_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a291660",
   "metadata": {
    "id": "3a291660"
   },
   "source": [
    "### Create the train dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "574373be",
   "metadata": {
    "id": "574373be"
   },
   "outputs": [],
   "source": [
    "# fill this in\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, \n",
    "                     batch_size=TRAIN_BATCH, \n",
    "                     shuffle=True, \n",
    "                     num_workers=WORKERS,\n",
    "                     pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6aa623fe",
   "metadata": {
    "id": "6aa623fe"
   },
   "outputs": [],
   "source": [
    "# fill this in..\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, \n",
    "                            batch_size=VAL_BATCH,\n",
    "                            shuffle=False, \n",
    "                            num_workers=WORKERS,\n",
    "                            pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7cfa6766",
   "metadata": {
    "id": "7cfa6766"
   },
   "outputs": [],
   "source": [
    "best_acc1 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0d0620a6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0d0620a6",
    "outputId": "7b7f29f6-75c9-40cf-8430-9bec156609d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][   0/1252]\tTime 10.901 (10.901)\tData  5.794 ( 5.794)\tLoss 8.0101e-01 (8.0101e-01)\tAcc@1  77.73 ( 77.73)\tAcc@5  94.92 ( 94.92)\n",
      "Epoch: [0][  50/1252]\tTime  6.500 ( 6.226)\tData  5.930 ( 5.566)\tLoss 2.4359e+00 (2.7937e+00)\tAcc@1  45.70 ( 39.09)\tAcc@5  71.19 ( 64.77)\n",
      "Epoch: [0][ 100/1252]\tTime  6.268 ( 6.337)\tData  5.697 ( 5.721)\tLoss 2.2943e+00 (2.5967e+00)\tAcc@1  46.19 ( 42.02)\tAcc@5  73.24 ( 68.41)\n",
      "Epoch: [0][ 150/1252]\tTime  6.302 ( 6.373)\tData  5.732 ( 5.772)\tLoss 2.2241e+00 (2.4613e+00)\tAcc@1  48.14 ( 44.36)\tAcc@5  73.54 ( 70.73)\n",
      "Epoch: [0][ 200/1252]\tTime  6.250 ( 6.392)\tData  5.680 ( 5.798)\tLoss 2.2690e+00 (2.3696e+00)\tAcc@1  47.66 ( 45.98)\tAcc@5  74.12 ( 72.34)\n",
      "Epoch: [0][ 250/1252]\tTime  6.260 ( 6.385)\tData  5.690 ( 5.796)\tLoss 2.0989e+00 (2.3129e+00)\tAcc@1  53.12 ( 46.97)\tAcc@5  75.88 ( 73.36)\n",
      "Epoch: [0][ 300/1252]\tTime  6.351 ( 6.390)\tData  5.781 ( 5.804)\tLoss 2.0651e+00 (2.2707e+00)\tAcc@1  53.42 ( 47.78)\tAcc@5  78.91 ( 74.15)\n",
      "Epoch: [0][ 350/1252]\tTime  6.305 ( 6.396)\tData  5.735 ( 5.813)\tLoss 2.2163e+00 (2.2403e+00)\tAcc@1  49.61 ( 48.36)\tAcc@5  75.78 ( 74.67)\n",
      "Epoch: [0][ 400/1252]\tTime  6.376 ( 6.397)\tData  5.805 ( 5.815)\tLoss 2.0946e+00 (2.2219e+00)\tAcc@1  51.07 ( 48.71)\tAcc@5  76.56 ( 75.02)\n",
      "Epoch: [0][ 450/1252]\tTime  6.659 ( 6.404)\tData  6.089 ( 5.824)\tLoss 2.0749e+00 (2.2051e+00)\tAcc@1  52.54 ( 49.06)\tAcc@5  77.15 ( 75.31)\n",
      "Epoch: [0][ 500/1252]\tTime  6.403 ( 6.408)\tData  5.833 ( 5.828)\tLoss 2.0612e+00 (2.1946e+00)\tAcc@1  52.34 ( 49.28)\tAcc@5  78.03 ( 75.51)\n",
      "Epoch: [0][ 550/1252]\tTime  6.382 ( 6.414)\tData  5.811 ( 5.835)\tLoss 1.9299e+00 (2.1860e+00)\tAcc@1  53.12 ( 49.46)\tAcc@5  80.66 ( 75.66)\n",
      "Epoch: [0][ 600/1252]\tTime  6.602 ( 6.421)\tData  6.030 ( 5.843)\tLoss 2.1049e+00 (2.1765e+00)\tAcc@1  51.76 ( 49.64)\tAcc@5  77.64 ( 75.85)\n",
      "Epoch: [0][ 650/1252]\tTime  6.263 ( 6.424)\tData  5.693 ( 5.847)\tLoss 2.2194e+00 (2.1720e+00)\tAcc@1  47.85 ( 49.74)\tAcc@5  75.00 ( 75.94)\n",
      "Epoch: [0][ 700/1252]\tTime  6.645 ( 6.426)\tData  6.074 ( 5.849)\tLoss 2.2532e+00 (2.1684e+00)\tAcc@1  49.32 ( 49.83)\tAcc@5  75.10 ( 76.01)\n",
      "Epoch: [0][ 750/1252]\tTime  6.349 ( 6.428)\tData  5.779 ( 5.852)\tLoss 2.2446e+00 (2.1673e+00)\tAcc@1  48.54 ( 49.85)\tAcc@5  75.39 ( 76.05)\n",
      "Epoch: [0][ 800/1252]\tTime  6.413 ( 6.431)\tData  5.842 ( 5.854)\tLoss 2.2055e+00 (2.1651e+00)\tAcc@1  50.00 ( 49.89)\tAcc@5  75.29 ( 76.10)\n",
      "Epoch: [0][ 850/1252]\tTime  6.480 ( 6.432)\tData  5.910 ( 5.856)\tLoss 2.2018e+00 (2.1648e+00)\tAcc@1  49.71 ( 49.90)\tAcc@5  76.46 ( 76.10)\n",
      "Epoch: [0][ 900/1252]\tTime  6.454 ( 6.434)\tData  5.883 ( 5.859)\tLoss 2.2359e+00 (2.1640e+00)\tAcc@1  48.14 ( 49.93)\tAcc@5  75.20 ( 76.14)\n",
      "Epoch: [0][ 950/1252]\tTime  6.660 ( 6.437)\tData  6.089 ( 5.861)\tLoss 2.2216e+00 (2.1657e+00)\tAcc@1  47.85 ( 49.92)\tAcc@5  75.29 ( 76.11)\n",
      "Epoch: [0][1000/1252]\tTime  6.708 ( 6.439)\tData  6.138 ( 5.864)\tLoss 2.2040e+00 (2.1663e+00)\tAcc@1  49.71 ( 49.90)\tAcc@5  75.29 ( 76.10)\n",
      "Epoch: [0][1050/1252]\tTime  6.628 ( 6.442)\tData  6.056 ( 5.867)\tLoss 2.2840e+00 (2.1666e+00)\tAcc@1  48.14 ( 49.90)\tAcc@5  73.93 ( 76.10)\n",
      "Epoch: [0][1100/1252]\tTime  6.895 ( 6.444)\tData  6.325 ( 5.869)\tLoss 2.2269e+00 (2.1675e+00)\tAcc@1  50.39 ( 49.89)\tAcc@5  75.10 ( 76.09)\n",
      "Epoch: [0][1150/1252]\tTime  6.544 ( 6.445)\tData  5.973 ( 5.871)\tLoss 2.1859e+00 (2.1690e+00)\tAcc@1  49.51 ( 49.87)\tAcc@5  75.88 ( 76.06)\n",
      "Epoch: [0][1200/1252]\tTime  6.472 ( 6.448)\tData  5.901 ( 5.874)\tLoss 2.2519e+00 (2.1710e+00)\tAcc@1  48.93 ( 49.82)\tAcc@5  74.80 ( 76.04)\n",
      "Epoch: [0][1250/1252]\tTime  6.300 ( 6.450)\tData  5.730 ( 5.875)\tLoss 2.0699e+00 (2.1726e+00)\tAcc@1  52.05 ( 49.80)\tAcc@5  77.25 ( 76.02)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py\", line 61, in fetch\n    return self.collate_fn(data)\n  File \"/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/collate.py\", line 265, in default_collate\n    return collate(batch, collate_fn_map=default_collate_fn_map)\n  File \"/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/collate.py\", line 143, in collate\n    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.\n  File \"/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/collate.py\", line 143, in <listcomp>\n    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.\n  File \"/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/collate.py\", line 120, in collate\n    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)\n  File \"/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/collate.py\", line 163, in collate_tensor_fn\n    return torch.stack(batch, 0, out=out)\nRuntimeError: stack expects each tensor to be equal size, but got [3, 375, 500] at entry 0 and [3, 399, 500] at entry 10\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:15\u001b[0m\n",
      "Cell \u001b[0;32mIn[10], line 16\u001b[0m, in \u001b[0;36mvalidate\u001b[0;34m(val_loader, model, criterion)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mamp\u001b[38;5;241m.\u001b[39mautocast():\n\u001b[1;32m     15\u001b[0m     end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 16\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, (images, target) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(val_loader):\n\u001b[1;32m     17\u001b[0m         \n\u001b[1;32m     18\u001b[0m         \u001b[38;5;66;03m# pad the input images to the same length\u001b[39;00m\n\u001b[1;32m     19\u001b[0m         \u001b[38;5;66;03m#images = pad_sequence(images, batch_first=True)\u001b[39;00m\n\u001b[1;32m     20\u001b[0m         \n\u001b[1;32m     21\u001b[0m         \u001b[38;5;66;03m### send the images and target to cuda\u001b[39;00m\n\u001b[1;32m     22\u001b[0m         images \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[1;32m     23\u001b[0m         target \u001b[38;5;241m=\u001b[39m target\u001b[38;5;241m.\u001b[39mcuda()\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:635\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    633\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    634\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 635\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    636\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    637\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    638\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    639\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:1347\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1345\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1346\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_info[idx]\n\u001b[0;32m-> 1347\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:1373\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1371\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_put_index()\n\u001b[1;32m   1372\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[0;32m-> 1373\u001b[0m     \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1374\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/_utils.py:636\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    633\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    634\u001b[0m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    635\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m--> 636\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py\", line 61, in fetch\n    return self.collate_fn(data)\n  File \"/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/collate.py\", line 265, in default_collate\n    return collate(batch, collate_fn_map=default_collate_fn_map)\n  File \"/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/collate.py\", line 143, in collate\n    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.\n  File \"/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/collate.py\", line 143, in <listcomp>\n    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.\n  File \"/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/collate.py\", line 120, in collate\n    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)\n  File \"/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/collate.py\", line 163, in collate_tensor_fn\n    return torch.stack(batch, 0, out=out)\nRuntimeError: stack expects each tensor to be equal size, but got [3, 375, 500] at entry 0 and [3, 399, 500] at entry 10\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# create TensorBoard summary writer\n",
    "log_dir = '/workspace/w251-hw9/logs'\n",
    "writer = SummaryWriter(log_dir)\n",
    "\n",
    "# print log directory path\n",
    "#print('Log directory path:', writer.log_dir)\n",
    "\n",
    "for epoch in range(START_EPOCH, EPOCHS):\n",
    "#    adjust_learning_rate(optimizer, epoch)\n",
    "\n",
    "    # train for one epoch\n",
    "    train(train_loader, model, criterion, optimizer, epoch)\n",
    "\n",
    "    # evaluate on validation set\n",
    "    acc1 = validate(val_loader, model, criterion)\n",
    "\n",
    "    # remember best acc@1 and save checkpoint\n",
    "    is_best = acc1 > best_acc1\n",
    "    best_acc1 = max(acc1, best_acc1)\n",
    "\n",
    "\n",
    "    if RANK == 0:\n",
    "        save_checkpoint({\n",
    "            'epoch': epoch + 1,\n",
    "            'arch': ARCH,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'best_acc1': best_acc1,\n",
    "            'optimizer' : optimizer.state_dict(),\n",
    "        }, is_best)\n",
    "    \n",
    "    scheduler.step()\n",
    "    print('lr: ' + str(scheduler.get_last_lr()))\n",
    "    \n",
    "    # write to TensorBoard\n",
    "    writer.add_scalar('Training Loss', train_loss, epoch)\n",
    "    writer.add_scalar('Validation Accuracy', acc1, epoch)\n",
    "    \n",
    "# close TensorBoard writer\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c4cb64",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "45c4cb64",
    "outputId": "996942c0-1c50-4d8f-d0a6-481c3de7200e"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42384b4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "11839112304746f9a7fd76784958faa4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e952a4ef79f2406082f01c1ef44be20e",
      "max": 46830571,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e62345a5fe3244e3ad50cee5ff01ae93",
      "value": 46830571
     }
    },
    "2a592d63a5b24791ad351b5c911fac65": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2a86b108d37548eba7e5042a00f6d63a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3ed3d41696734302b0a8c2bb5a9026cc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4205c04d3e5c4244b144861a9263a322",
       "IPY_MODEL_11839112304746f9a7fd76784958faa4",
       "IPY_MODEL_ae70f8cd257b47cc9af26e1dc7c1ec38"
      ],
      "layout": "IPY_MODEL_620dae24fc9e4be0b245c019bfb7f4c5"
     }
    },
    "4205c04d3e5c4244b144861a9263a322": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dee11a91c86e4ca1a05b7cb62af41fee",
      "placeholder": "​",
      "style": "IPY_MODEL_48c5147a2da546af988e4dea6703653a",
      "value": "100%"
     }
    },
    "48c5147a2da546af988e4dea6703653a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "620dae24fc9e4be0b245c019bfb7f4c5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ae70f8cd257b47cc9af26e1dc7c1ec38": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2a86b108d37548eba7e5042a00f6d63a",
      "placeholder": "​",
      "style": "IPY_MODEL_2a592d63a5b24791ad351b5c911fac65",
      "value": " 44.7M/44.7M [00:00&lt;00:00, 59.7MB/s]"
     }
    },
    "dee11a91c86e4ca1a05b7cb62af41fee": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e62345a5fe3244e3ad50cee5ff01ae93": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e952a4ef79f2406082f01c1ef44be20e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
