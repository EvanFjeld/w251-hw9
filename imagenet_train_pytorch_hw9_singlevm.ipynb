{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8e83b8f",
   "metadata": {
    "id": "cace261f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim\n",
    "\n",
    "import torch.utils.data\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "import torch.distributed as dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1ca3756",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-13 01:51:40.157051: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-13 01:51:41.020164: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/compat/lib.real:/usr/local/lib/python3.8/dist-packages/torch/lib:/usr/local/lib/python3.8/dist-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda-11/lib64\n",
      "2023-03-13 01:51:41.020255: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/compat/lib.real:/usr/local/lib/python3.8/dist-packages/torch/lib:/usr/local/lib/python3.8/dist-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda-11/lib64\n",
      "2023-03-13 01:51:41.020262: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# create TensorBoard summary writer\n",
    "log_dir = '/workspace/w251-hw9/logs'\n",
    "writer = SummaryWriter(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbd0b3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPU=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a002c5e",
   "metadata": {
    "id": "363e2b75"
   },
   "outputs": [],
   "source": [
    "SEED=1\n",
    "\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "cudnn.deterministic = True\n",
    "\n",
    "scaler = GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c13d39f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70e38781",
   "metadata": {
    "id": "0d479743"
   },
   "outputs": [],
   "source": [
    "START_EPOCH = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "521ffc24",
   "metadata": {
    "id": "97b1a0aa",
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "ARCH = 'resnet18'\n",
    "EPOCHS = 2\n",
    "LR = 0.1\n",
    "MOMENTUM = 0.9\n",
    "WEIGHT_DECAY = 5e-4\n",
    "PRINT_FREQ = 50\n",
    "TRAIN_BATCH=1024\n",
    "VAL_BATCH=1024\n",
    "WORKERS=1\n",
    "RANK=0\n",
    "\n",
    "TRAINDIR=\"/data/train\"\n",
    "VALDIR=\"/data/val\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7a1ea3",
   "metadata": {
    "id": "e86c3188"
   },
   "source": [
    "### Check if cuda is available here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4fbbdb07",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "63a0499b",
    "outputId": "4a90cd73-a4b2-42ea-fb9a-e3afb36f2063"
   },
   "outputs": [],
   "source": [
    "# check if cuda is available in this cell\n",
    "# if it is not available, you should not go forward!\n",
    "if not torch.cuda.is_available():\n",
    "    print(\"GPU not detected...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36d1245d",
   "metadata": {
    "id": "1e5ddf20"
   },
   "outputs": [],
   "source": [
    "# set your active device to your GPU in this cell\n",
    "#device = torch.device(\"cuda\")\n",
    "GPU = torch.device('cuda:0')\n",
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c04e1f",
   "metadata": {
    "id": "7cdd6e12"
   },
   "source": [
    "### Fill in the heart of the train section below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b01bfbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_step = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "753d95e2",
   "metadata": {
    "id": "70dbd4c4"
   },
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, epoch):\n",
    "    global global_step\n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    data_time = AverageMeter('Data', ':6.3f')\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "    top5 = AverageMeter('Acc@5', ':6.2f')\n",
    "    progress = ProgressMeter(\n",
    "        len(train_loader),\n",
    "        [batch_time, data_time, losses, top1, top5],\n",
    "        prefix=\"Epoch: [{}]\".format(epoch))\n",
    "\n",
    "    ######################\n",
    "    # switch model to train mode here\n",
    "    model.train()\n",
    "    ################\n",
    "    \n",
    "    end = time.time()\n",
    "    for i, (images, target) in enumerate(train_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        #####################\n",
    "        if GPU is not None:\n",
    "            # send the images to cuda device\n",
    "            images = images.cuda(GPU, non_blocking=True)\n",
    "        if torch.cuda.is_available():\n",
    "            # send the target to cuda device\n",
    "            target = target.cuda(GPU, non_blocking=True)\n",
    "\n",
    "        \n",
    "        with autocast():\n",
    "            # compute output\n",
    "            output = model(images)\n",
    "            # compute loss\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "        losses.update(loss.item(), images.size(0))\n",
    "        top1.update(acc1[0], images.size(0))\n",
    "        top5.update(acc5[0], images.size(0))\n",
    "\n",
    "\n",
    "        #### zero out gradients in the optimier\n",
    "        optimizer.zero_grad()\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        \n",
    "        writer.add_scalar(\"Loss/train\", loss, global_step = global_step)\n",
    "        writer.add_scalar(\"acc1/train\", top1.avg, global_step = global_step)\n",
    "        writer.add_scalar(\"acc5/train\", top5.avg, global_step = global_step)\n",
    "        global_step = global_step + 1\n",
    "\n",
    "        if i % PRINT_FREQ == 0:\n",
    "            progress.display(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78dbc3b3",
   "metadata": {
    "id": "deb3b62e"
   },
   "source": [
    "#### Fill in the validate section below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a68655d",
   "metadata": {
    "id": "a3f276cc"
   },
   "outputs": [],
   "source": [
    "def validate(val_loader, model, criterion):\n",
    "    global global_step\n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "    top5 = AverageMeter('Acc@5', ':6.2f')\n",
    "    progress = ProgressMeter(\n",
    "        len(val_loader),\n",
    "        [batch_time, losses, top1, top5],\n",
    "        prefix='Test: ')\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        end = time.time()\n",
    "        for i, (images, target) in enumerate(val_loader):\n",
    "            \n",
    "            if GPU is not None:\n",
    "                images = images.cuda(GPU, non_blocking=True)\n",
    "            if torch.cuda.is_available():\n",
    "                target = target.cuda(GPU, non_blocking=True)\n",
    "\n",
    "            # compute output & loss\n",
    "            output = model(images)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "            losses.update(loss.item(), images.size(0))\n",
    "            top1.update(acc1[0], images.size(0))\n",
    "            top5.update(acc5[0], images.size(0))\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            if i % PRINT_FREQ == 0:\n",
    "                progress.display(i)\n",
    "        \n",
    "        writer.add_scalar(\"Loss/val\", loss, global_step = global_step)\n",
    "        writer.add_scalar(\"acc1/val\", top1.avg, global_step = global_step)\n",
    "        writer.add_scalar(\"acc5/val\", top5.avg, global_step = global_step)\n",
    "        global_step = global_step + 1\n",
    "        \n",
    "        # TODO: this should also be done with the ProgressMeter\n",
    "        print(' * Acc@1 {top1.avg:.3f} Acc@5 {top5.avg:.3f}'\n",
    "              .format(top1=top1, top5=top5))\n",
    "\n",
    "    return top1.avg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e9994e",
   "metadata": {
    "id": "fbe49226"
   },
   "source": [
    "### Save the checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "72028b16",
   "metadata": {
    "id": "ff8a4159"
   },
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best, filename='checkpoints/single_vm_checkpoint.pth.tar'):\n",
    "    # save the model state!\n",
    "    torch.save(state, filename)\n",
    "    \n",
    "    if is_best:\n",
    "        shutil.copyfile(filename, 'checkpoints/single_vm_model_best.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e1886174",
   "metadata": {
    "id": "1cd7ea3a"
   },
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self, name, fmt=':f'):\n",
    "        self.name = name\n",
    "        self.fmt = fmt\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def __str__(self):\n",
    "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
    "        return fmtstr.format(**self.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1a19c35f",
   "metadata": {
    "id": "e1da87ab"
   },
   "outputs": [],
   "source": [
    "class ProgressMeter(object):\n",
    "    def __init__(self, num_batches, meters, prefix=\"\"):\n",
    "        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n",
    "        self.meters = meters\n",
    "        self.prefix = prefix\n",
    "\n",
    "    def display(self, batch):\n",
    "        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n",
    "        entries += [str(meter) for meter in self.meters]\n",
    "        print('\\t'.join(entries))\n",
    "\n",
    "    def _get_batch_fmtstr(self, num_batches):\n",
    "        num_digits = len(str(num_batches // 1))\n",
    "        fmt = '{:' + str(num_digits) + 'd}'\n",
    "        return '[' + fmt + '/' + fmt.format(num_batches) + ']'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c547c492",
   "metadata": {
    "id": "00211030"
   },
   "outputs": [],
   "source": [
    "# if we are adjusting the LR manually use this\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
    "    lr = LR * (0.1 ** (epoch // 30))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4262d99d",
   "metadata": {
    "id": "da2c1382"
   },
   "outputs": [],
   "source": [
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4ee8ef1d",
   "metadata": {
    "id": "5c29e7a1"
   },
   "outputs": [],
   "source": [
    "imagenet_mean_RGB = [0.47889522, 0.47227842, 0.43047404]\n",
    "imagenet_std_RGB = [0.24205776, 0.23828046, 0.25874835]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "be0d8181",
   "metadata": {
    "id": "e1a61c02"
   },
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=imagenet_mean_RGB, std=imagenet_std_RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "45b689b2",
   "metadata": {
    "id": "47dd3e49"
   },
   "outputs": [],
   "source": [
    "IMG_SIZE = 224\n",
    "INPUT_SIZE = 256\n",
    "NUM_CLASSES = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c345d75",
   "metadata": {
    "id": "de4387cb"
   },
   "source": [
    "### Initialize the model using the architecture you selected above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "109e8a76",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 158,
     "referenced_widgets": [
      "3ed3d41696734302b0a8c2bb5a9026cc",
      "4205c04d3e5c4244b144861a9263a322",
      "11839112304746f9a7fd76784958faa4",
      "ae70f8cd257b47cc9af26e1dc7c1ec38",
      "620dae24fc9e4be0b245c019bfb7f4c5",
      "dee11a91c86e4ca1a05b7cb62af41fee",
      "48c5147a2da546af988e4dea6703653a",
      "e952a4ef79f2406082f01c1ef44be20e",
      "e62345a5fe3244e3ad50cee5ff01ae93",
      "2a86b108d37548eba7e5042a00f6d63a",
      "2a592d63a5b24791ad351b5c911fac65"
     ]
    },
    "id": "b1abcc33",
    "outputId": "a35b9eae-97fa-4402-b2bb-c7330adaf1ba"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# select the model\n",
    "model = models.__dict__[ARCH](pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "47550d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "inf = model.fc.in_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1f02b6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fc = nn.Linear(inf,NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea18a6ad",
   "metadata": {
    "id": "2db1bb69"
   },
   "source": [
    "### Send the model to the cuda device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "38ee5c07",
   "metadata": {
    "id": "7d23ccb4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cuda(GPU)\n",
    "next(model.parameters()).is_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3110c888",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46861312"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.memory_allocated()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caac2729",
   "metadata": {
    "id": "47a8eb8d"
   },
   "source": [
    "### Instantiate the loss to cross entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "280cbbfe",
   "metadata": {
    "id": "a49ae3c9"
   },
   "outputs": [],
   "source": [
    "# use the cross-entropy loss\n",
    "criterion = nn.CrossEntropyLoss().cuda(GPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f3f8fc",
   "metadata": {
    "id": "8a49045a"
   },
   "source": [
    "### Instantiate the optimizer to SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1c599df3",
   "metadata": {
    "id": "aa3a04dd"
   },
   "outputs": [],
   "source": [
    "# use SGD .. use the momentum and weight decay vars\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LR, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2198cb",
   "metadata": {
    "id": "f93ef11d"
   },
   "source": [
    "#### Create the learning rate scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "528490cd",
   "metadata": {
    "id": "a0e1727a"
   },
   "outputs": [],
   "source": [
    "# use CosineAnnealingLR\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS, eta_min=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b17d0958",
   "metadata": {
    "id": "2fe08caa"
   },
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize(INPUT_SIZE),\n",
    "    transforms.CenterCrop(IMG_SIZE),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(imagenet_mean_RGB, imagenet_std_RGB),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bbcc58f",
   "metadata": {
    "id": "236528e1"
   },
   "source": [
    "### Create the train dataset object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d4660e70",
   "metadata": {
    "id": "7c29f6b1"
   },
   "outputs": [],
   "source": [
    "train_dataset = datasets.ImageFolder(root=TRAINDIR, \n",
    "                                     transform=transform_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8055508c",
   "metadata": {
    "id": "63dfe3c0"
   },
   "outputs": [],
   "source": [
    "transform_val = transforms.Compose([\n",
    "    transforms.Resize(INPUT_SIZE),\n",
    "    transforms.CenterCrop(IMG_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(imagenet_mean_RGB, imagenet_std_RGB),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a33f95",
   "metadata": {
    "id": "38ca6c39"
   },
   "source": [
    "### Create the val dataset object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d13f093c",
   "metadata": {
    "id": "42d58f82"
   },
   "outputs": [],
   "source": [
    "# use torchvision.datasets.CIFAR10\n",
    "# val_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_val)\n",
    "val_dataset = datasets.ImageFolder(root=VALDIR, transform=transform_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f0a5ae",
   "metadata": {
    "id": "3a291660"
   },
   "source": [
    "### Create the train dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1f6fc8fe",
   "metadata": {
    "id": "574373be"
   },
   "outputs": [],
   "source": [
    "# fill this in\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, \n",
    "                     batch_size=TRAIN_BATCH, \n",
    "                     shuffle=True, \n",
    "                     num_workers=WORKERS,\n",
    "                     pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "29b35609",
   "metadata": {
    "id": "6aa623fe"
   },
   "outputs": [],
   "source": [
    "# fill this in..\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, \n",
    "                            batch_size=VAL_BATCH,\n",
    "                            shuffle=False, \n",
    "                            num_workers=WORKERS,\n",
    "                            pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6b67319f",
   "metadata": {
    "id": "7cfa6766"
   },
   "outputs": [],
   "source": [
    "best_acc1 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42aba96",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0d0620a6",
    "outputId": "7b7f29f6-75c9-40cf-8430-9bec156609d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][   0/1252]\tTime 12.266 (12.266)\tData  7.424 ( 7.424)\tLoss 7.1260e+00 (7.1260e+00)\tAcc@1   0.10 (  0.10)\tAcc@5   0.68 (  0.68)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for epoch in range(START_EPOCH, EPOCHS):\n",
    "#    adjust_learning_rate(optimizer, epoch)\n",
    "\n",
    "    # train for one epoch\n",
    "    train(train_loader, model, criterion, optimizer, epoch)\n",
    "\n",
    "    # evaluate on validation set\n",
    "    acc1 = validate(val_loader, model, criterion)\n",
    "\n",
    "    # remember best acc@1 and save checkpoint\n",
    "    is_best = acc1 > best_acc1\n",
    "    best_acc1 = max(acc1, best_acc1)\n",
    "\n",
    "    if RANK == 0:\n",
    "        save_checkpoint({\n",
    "            'epoch': epoch + 1,\n",
    "            'arch': ARCH,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'best_acc1': best_acc1,\n",
    "            'optimizer' : optimizer.state_dict(),\n",
    "        }, is_best)\n",
    "    \n",
    "    scheduler.step()\n",
    "    print('lr: ' + str(scheduler.get_last_lr()))\n",
    "    \n",
    "# close TensorBoard writer\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "970f1763",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "45c4cb64",
    "outputId": "996942c0-1c50-4d8f-d0a6-481c3de7200e"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f69466",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "11839112304746f9a7fd76784958faa4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e952a4ef79f2406082f01c1ef44be20e",
      "max": 46830571,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e62345a5fe3244e3ad50cee5ff01ae93",
      "value": 46830571
     }
    },
    "2a592d63a5b24791ad351b5c911fac65": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2a86b108d37548eba7e5042a00f6d63a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3ed3d41696734302b0a8c2bb5a9026cc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4205c04d3e5c4244b144861a9263a322",
       "IPY_MODEL_11839112304746f9a7fd76784958faa4",
       "IPY_MODEL_ae70f8cd257b47cc9af26e1dc7c1ec38"
      ],
      "layout": "IPY_MODEL_620dae24fc9e4be0b245c019bfb7f4c5"
     }
    },
    "4205c04d3e5c4244b144861a9263a322": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dee11a91c86e4ca1a05b7cb62af41fee",
      "placeholder": "​",
      "style": "IPY_MODEL_48c5147a2da546af988e4dea6703653a",
      "value": "100%"
     }
    },
    "48c5147a2da546af988e4dea6703653a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "620dae24fc9e4be0b245c019bfb7f4c5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ae70f8cd257b47cc9af26e1dc7c1ec38": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2a86b108d37548eba7e5042a00f6d63a",
      "placeholder": "​",
      "style": "IPY_MODEL_2a592d63a5b24791ad351b5c911fac65",
      "value": " 44.7M/44.7M [00:00&lt;00:00, 59.7MB/s]"
     }
    },
    "dee11a91c86e4ca1a05b7cb62af41fee": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e62345a5fe3244e3ad50cee5ff01ae93": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e952a4ef79f2406082f01c1ef44be20e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
