{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d05e0ff9",
   "metadata": {
    "id": "cace261f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim\n",
    "\n",
    "import torch.utils.data\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "import torch.distributed as dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0eed3d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-13 02:05:13.012162: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-13 02:05:13.860198: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/compat/lib.real:/usr/local/lib/python3.8/dist-packages/torch/lib:/usr/local/lib/python3.8/dist-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda-11/lib64\n",
      "2023-03-13 02:05:13.860284: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/compat/lib.real:/usr/local/lib/python3.8/dist-packages/torch/lib:/usr/local/lib/python3.8/dist-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda-11/lib64\n",
      "2023-03-13 02:05:13.860290: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# create TensorBoard summary writer\n",
    "log_dir = '/workspace/w251-hw9/logs'\n",
    "writer = SummaryWriter(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21e54fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPU=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1494e66d",
   "metadata": {
    "id": "363e2b75"
   },
   "outputs": [],
   "source": [
    "SEED=1\n",
    "\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "cudnn.deterministic = True\n",
    "\n",
    "scaler = GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab1899d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf354fb5",
   "metadata": {
    "id": "0d479743"
   },
   "outputs": [],
   "source": [
    "START_EPOCH = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65219777",
   "metadata": {
    "id": "97b1a0aa",
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "ARCH = 'resnet18'\n",
    "EPOCHS = 2\n",
    "LR = 0.1\n",
    "MOMENTUM = 0.9\n",
    "WEIGHT_DECAY = 5e-4\n",
    "PRINT_FREQ = 50\n",
    "TRAIN_BATCH=1024\n",
    "VAL_BATCH=1024\n",
    "WORKERS=1\n",
    "RANK=0\n",
    "\n",
    "TRAINDIR=\"/data/train\"\n",
    "VALDIR=\"/data/val\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8edfdd45",
   "metadata": {
    "id": "e86c3188"
   },
   "source": [
    "### Check if cuda is available here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1dae0bb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "63a0499b",
    "outputId": "4a90cd73-a4b2-42ea-fb9a-e3afb36f2063"
   },
   "outputs": [],
   "source": [
    "# check if cuda is available in this cell\n",
    "# if it is not available, you should not go forward!\n",
    "if not torch.cuda.is_available():\n",
    "    print(\"GPU not detected...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9654edf",
   "metadata": {
    "id": "1e5ddf20"
   },
   "outputs": [],
   "source": [
    "# set your active device to your GPU in this cell\n",
    "#device = torch.device(\"cuda\")\n",
    "GPU = torch.device('cuda:0')\n",
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58a4e74",
   "metadata": {
    "id": "7cdd6e12"
   },
   "source": [
    "### Fill in the heart of the train section below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9dc8726",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_step = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57279c09",
   "metadata": {
    "id": "70dbd4c4"
   },
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, epoch):\n",
    "    global global_step\n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    data_time = AverageMeter('Data', ':6.3f')\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "    top5 = AverageMeter('Acc@5', ':6.2f')\n",
    "    progress = ProgressMeter(\n",
    "        len(train_loader),\n",
    "        [batch_time, data_time, losses, top1, top5],\n",
    "        prefix=\"Epoch: [{}]\".format(epoch))\n",
    "\n",
    "    ######################\n",
    "    # switch model to train mode here\n",
    "    model.train()\n",
    "    ################\n",
    "    \n",
    "    end = time.time()\n",
    "    for i, (images, target) in enumerate(train_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        #####################\n",
    "        if GPU is not None:\n",
    "            # send the images to cuda device\n",
    "            images = images.cuda(GPU, non_blocking=True)\n",
    "        if torch.cuda.is_available():\n",
    "            # send the target to cuda device\n",
    "            target = target.cuda(GPU, non_blocking=True)\n",
    "\n",
    "        \n",
    "        with autocast():\n",
    "            # compute output\n",
    "            output = model(images)\n",
    "            # compute loss\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "        losses.update(loss.item(), images.size(0))\n",
    "        top1.update(acc1[0], images.size(0))\n",
    "        top5.update(acc5[0], images.size(0))\n",
    "\n",
    "\n",
    "        #### zero out gradients in the optimier\n",
    "        optimizer.zero_grad()\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        \n",
    "        writer.add_scalar(\"Loss/train\", loss, global_step = global_step)\n",
    "        writer.add_scalar(\"acc1/train\", top1.avg, global_step = global_step)\n",
    "        writer.add_scalar(\"acc5/train\", top5.avg, global_step = global_step)\n",
    "        global_step = global_step + 1\n",
    "\n",
    "        if i % PRINT_FREQ == 0:\n",
    "            progress.display(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ea0dd7",
   "metadata": {
    "id": "deb3b62e"
   },
   "source": [
    "#### Fill in the validate section below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ddc96470",
   "metadata": {
    "id": "a3f276cc"
   },
   "outputs": [],
   "source": [
    "def validate(val_loader, model, criterion):\n",
    "    global global_step\n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "    top5 = AverageMeter('Acc@5', ':6.2f')\n",
    "    progress = ProgressMeter(\n",
    "        len(val_loader),\n",
    "        [batch_time, losses, top1, top5],\n",
    "        prefix='Test: ')\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        end = time.time()\n",
    "        for i, (images, target) in enumerate(val_loader):\n",
    "            \n",
    "            if GPU is not None:\n",
    "                images = images.cuda(GPU, non_blocking=True)\n",
    "            if torch.cuda.is_available():\n",
    "                target = target.cuda(GPU, non_blocking=True)\n",
    "\n",
    "            # compute output & loss\n",
    "            output = model(images)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "            losses.update(loss.item(), images.size(0))\n",
    "            top1.update(acc1[0], images.size(0))\n",
    "            top5.update(acc5[0], images.size(0))\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            if i % PRINT_FREQ == 0:\n",
    "                progress.display(i)\n",
    "        \n",
    "        writer.add_scalar(\"Loss/val\", loss, global_step = global_step)\n",
    "        writer.add_scalar(\"acc1/val\", top1.avg, global_step = global_step)\n",
    "        writer.add_scalar(\"acc5/val\", top5.avg, global_step = global_step)\n",
    "        global_step = global_step + 1\n",
    "        \n",
    "        # TODO: this should also be done with the ProgressMeter\n",
    "        print(' * Acc@1 {top1.avg:.3f} Acc@5 {top5.avg:.3f}'\n",
    "              .format(top1=top1, top5=top5))\n",
    "\n",
    "    return top1.avg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c06a82f",
   "metadata": {
    "id": "fbe49226"
   },
   "source": [
    "### Save the checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d8ecb1e8",
   "metadata": {
    "id": "ff8a4159"
   },
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best, filename='checkpoints/single_vm_checkpoint.pth.tar'):\n",
    "    # save the model state!\n",
    "    torch.save(state, filename)\n",
    "    \n",
    "    if is_best:\n",
    "        shutil.copyfile(filename, 'checkpoints/single_vm_model_best.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "79a6106d",
   "metadata": {
    "id": "1cd7ea3a"
   },
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self, name, fmt=':f'):\n",
    "        self.name = name\n",
    "        self.fmt = fmt\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def __str__(self):\n",
    "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
    "        return fmtstr.format(**self.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "384f65b4",
   "metadata": {
    "id": "e1da87ab"
   },
   "outputs": [],
   "source": [
    "class ProgressMeter(object):\n",
    "    def __init__(self, num_batches, meters, prefix=\"\"):\n",
    "        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n",
    "        self.meters = meters\n",
    "        self.prefix = prefix\n",
    "\n",
    "    def display(self, batch):\n",
    "        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n",
    "        entries += [str(meter) for meter in self.meters]\n",
    "        print('\\t'.join(entries))\n",
    "\n",
    "    def _get_batch_fmtstr(self, num_batches):\n",
    "        num_digits = len(str(num_batches // 1))\n",
    "        fmt = '{:' + str(num_digits) + 'd}'\n",
    "        return '[' + fmt + '/' + fmt.format(num_batches) + ']'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6e6cddc1",
   "metadata": {
    "id": "00211030"
   },
   "outputs": [],
   "source": [
    "# if we are adjusting the LR manually use this\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
    "    lr = LR * (0.1 ** (epoch // 30))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "250db433",
   "metadata": {
    "id": "da2c1382"
   },
   "outputs": [],
   "source": [
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "52c04f7e",
   "metadata": {
    "id": "5c29e7a1"
   },
   "outputs": [],
   "source": [
    "imagenet_mean_RGB = [0.47889522, 0.47227842, 0.43047404]\n",
    "imagenet_std_RGB = [0.24205776, 0.23828046, 0.25874835]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9e5133d2",
   "metadata": {
    "id": "e1a61c02"
   },
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=imagenet_mean_RGB, std=imagenet_std_RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7e475a17",
   "metadata": {
    "id": "47dd3e49"
   },
   "outputs": [],
   "source": [
    "IMG_SIZE = 224\n",
    "INPUT_SIZE = 256\n",
    "NUM_CLASSES = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3227694f",
   "metadata": {
    "id": "de4387cb"
   },
   "source": [
    "### Initialize the model using the architecture you selected above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8866e2d3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 158,
     "referenced_widgets": [
      "3ed3d41696734302b0a8c2bb5a9026cc",
      "4205c04d3e5c4244b144861a9263a322",
      "11839112304746f9a7fd76784958faa4",
      "ae70f8cd257b47cc9af26e1dc7c1ec38",
      "620dae24fc9e4be0b245c019bfb7f4c5",
      "dee11a91c86e4ca1a05b7cb62af41fee",
      "48c5147a2da546af988e4dea6703653a",
      "e952a4ef79f2406082f01c1ef44be20e",
      "e62345a5fe3244e3ad50cee5ff01ae93",
      "2a86b108d37548eba7e5042a00f6d63a",
      "2a592d63a5b24791ad351b5c911fac65"
     ]
    },
    "id": "b1abcc33",
    "outputId": "a35b9eae-97fa-4402-b2bb-c7330adaf1ba"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# select the model\n",
    "model = models.__dict__[ARCH](pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5064037a",
   "metadata": {},
   "outputs": [],
   "source": [
    "inf = model.fc.in_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "068ada05",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fc = nn.Linear(inf,NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa233d8",
   "metadata": {
    "id": "2db1bb69"
   },
   "source": [
    "### Send the model to the cuda device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6bda3e2c",
   "metadata": {
    "id": "7d23ccb4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cuda(GPU)\n",
    "next(model.parameters()).is_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6887fd77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46861312"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.memory_allocated()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539d7d02",
   "metadata": {
    "id": "47a8eb8d"
   },
   "source": [
    "### Instantiate the loss to cross entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e8e70ce8",
   "metadata": {
    "id": "a49ae3c9"
   },
   "outputs": [],
   "source": [
    "# use the cross-entropy loss\n",
    "criterion = nn.CrossEntropyLoss().cuda(GPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bfd0754",
   "metadata": {
    "id": "8a49045a"
   },
   "source": [
    "### Instantiate the optimizer to SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bf9fff1d",
   "metadata": {
    "id": "aa3a04dd"
   },
   "outputs": [],
   "source": [
    "# use SGD .. use the momentum and weight decay vars\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LR, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782ae0a3",
   "metadata": {
    "id": "f93ef11d"
   },
   "source": [
    "#### Create the learning rate scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "862b2e31",
   "metadata": {
    "id": "a0e1727a"
   },
   "outputs": [],
   "source": [
    "# use CosineAnnealingLR\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS, eta_min=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "42334f47",
   "metadata": {
    "id": "2fe08caa"
   },
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize(INPUT_SIZE),\n",
    "    transforms.CenterCrop(IMG_SIZE),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(imagenet_mean_RGB, imagenet_std_RGB),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05c4104",
   "metadata": {
    "id": "236528e1"
   },
   "source": [
    "### Create the train dataset object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "def8246b",
   "metadata": {
    "id": "7c29f6b1"
   },
   "outputs": [],
   "source": [
    "train_dataset = datasets.ImageFolder(root=TRAINDIR, \n",
    "                                     transform=transform_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "35b4fd2e",
   "metadata": {
    "id": "63dfe3c0"
   },
   "outputs": [],
   "source": [
    "transform_val = transforms.Compose([\n",
    "    transforms.Resize(INPUT_SIZE),\n",
    "    transforms.CenterCrop(IMG_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(imagenet_mean_RGB, imagenet_std_RGB),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e94ba5",
   "metadata": {
    "id": "38ca6c39"
   },
   "source": [
    "### Create the val dataset object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d5e4f9fd",
   "metadata": {
    "id": "42d58f82"
   },
   "outputs": [],
   "source": [
    "# use torchvision.datasets.CIFAR10\n",
    "# val_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_val)\n",
    "val_dataset = datasets.ImageFolder(root=VALDIR, transform=transform_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140e723e",
   "metadata": {
    "id": "3a291660"
   },
   "source": [
    "### Create the train dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b53b6e3a",
   "metadata": {
    "id": "574373be"
   },
   "outputs": [],
   "source": [
    "# fill this in\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, \n",
    "                     batch_size=TRAIN_BATCH, \n",
    "                     shuffle=True, \n",
    "                     num_workers=WORKERS,\n",
    "                     pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8c0b6ef3",
   "metadata": {
    "id": "6aa623fe"
   },
   "outputs": [],
   "source": [
    "# fill this in..\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, \n",
    "                            batch_size=VAL_BATCH,\n",
    "                            shuffle=False, \n",
    "                            num_workers=WORKERS,\n",
    "                            pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ef5a175d",
   "metadata": {
    "id": "7cfa6766"
   },
   "outputs": [],
   "source": [
    "best_acc1 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "54cb8da8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0d0620a6",
    "outputId": "7b7f29f6-75c9-40cf-8430-9bec156609d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][   0/1252]\tTime 10.928 (10.928)\tData  6.082 ( 6.082)\tLoss 7.1260e+00 (7.1260e+00)\tAcc@1   0.10 (  0.10)\tAcc@5   0.68 (  0.68)\n",
      "Epoch: [0][  50/1252]\tTime  5.296 ( 5.329)\tData  4.727 ( 4.677)\tLoss 2.5539e+00 (4.4737e+00)\tAcc@1  46.68 ( 24.76)\tAcc@5  73.73 ( 44.95)\n",
      "Epoch: [0][ 100/1252]\tTime  6.021 ( 5.348)\tData  5.454 ( 4.738)\tLoss 1.8583e+00 (3.3156e+00)\tAcc@1  57.62 ( 38.60)\tAcc@5  84.18 ( 62.20)\n",
      "Epoch: [0][ 150/1252]\tTime  6.778 ( 5.705)\tData  6.210 ( 5.109)\tLoss 1.8893e+00 (2.8362e+00)\tAcc@1  54.39 ( 44.64)\tAcc@5  81.45 ( 68.90)\n",
      "Epoch: [0][ 200/1252]\tTime  6.550 ( 5.951)\tData  5.982 ( 5.362)\tLoss 1.7766e+00 (2.5805e+00)\tAcc@1  58.59 ( 47.87)\tAcc@5  83.01 ( 72.32)\n",
      "Epoch: [0][ 250/1252]\tTime  6.860 ( 6.102)\tData  6.292 ( 5.517)\tLoss 1.7409e+00 (2.4217e+00)\tAcc@1  57.71 ( 49.87)\tAcc@5  83.69 ( 74.46)\n",
      "Epoch: [0][ 300/1252]\tTime  6.759 ( 6.201)\tData  6.192 ( 5.619)\tLoss 1.7538e+00 (2.3120e+00)\tAcc@1  57.62 ( 51.22)\tAcc@5  82.71 ( 75.88)\n",
      "Epoch: [0][ 350/1252]\tTime  6.824 ( 6.284)\tData  6.257 ( 5.704)\tLoss 1.7356e+00 (2.2326e+00)\tAcc@1  59.38 ( 52.22)\tAcc@5  83.59 ( 76.87)\n",
      "Epoch: [0][ 400/1252]\tTime  6.673 ( 6.334)\tData  6.105 ( 5.755)\tLoss 1.6814e+00 (2.1720e+00)\tAcc@1  62.30 ( 53.00)\tAcc@5  83.11 ( 77.62)\n",
      "Epoch: [0][ 450/1252]\tTime  6.550 ( 6.375)\tData  5.983 ( 5.797)\tLoss 1.7226e+00 (2.1248e+00)\tAcc@1  59.18 ( 53.59)\tAcc@5  83.50 ( 78.21)\n",
      "Epoch: [0][ 500/1252]\tTime  6.701 ( 6.403)\tData  6.134 ( 5.827)\tLoss 1.7696e+00 (2.0892e+00)\tAcc@1  57.81 ( 54.02)\tAcc@5  82.91 ( 78.64)\n",
      "Epoch: [0][ 550/1252]\tTime  6.961 ( 6.431)\tData  6.393 ( 5.855)\tLoss 1.8055e+00 (2.0583e+00)\tAcc@1  58.79 ( 54.41)\tAcc@5  82.71 ( 79.02)\n",
      "Epoch: [0][ 600/1252]\tTime  6.749 ( 6.458)\tData  6.181 ( 5.883)\tLoss 1.8642e+00 (2.0338e+00)\tAcc@1  55.37 ( 54.70)\tAcc@5  79.69 ( 79.31)\n",
      "Epoch: [0][ 650/1252]\tTime  6.736 ( 6.474)\tData  6.167 ( 5.899)\tLoss 1.8535e+00 (2.0118e+00)\tAcc@1  55.47 ( 54.97)\tAcc@5  80.37 ( 79.57)\n",
      "Epoch: [0][ 700/1252]\tTime  6.814 ( 6.498)\tData  6.245 ( 5.924)\tLoss 1.7739e+00 (1.9947e+00)\tAcc@1  58.50 ( 55.19)\tAcc@5  82.71 ( 79.79)\n",
      "Epoch: [0][ 750/1252]\tTime  7.030 ( 6.519)\tData  6.461 ( 5.946)\tLoss 1.7724e+00 (1.9795e+00)\tAcc@1  58.98 ( 55.38)\tAcc@5  82.03 ( 79.96)\n",
      "Epoch: [0][ 800/1252]\tTime  6.584 ( 6.532)\tData  6.016 ( 5.959)\tLoss 1.7701e+00 (1.9663e+00)\tAcc@1  57.62 ( 55.54)\tAcc@5  83.50 ( 80.11)\n",
      "Epoch: [0][ 850/1252]\tTime  6.797 ( 6.544)\tData  6.228 ( 5.970)\tLoss 1.8089e+00 (1.9549e+00)\tAcc@1  56.05 ( 55.69)\tAcc@5  81.74 ( 80.25)\n",
      "Epoch: [0][ 900/1252]\tTime  6.392 ( 6.543)\tData  5.825 ( 5.970)\tLoss 1.7643e+00 (1.9441e+00)\tAcc@1  57.81 ( 55.82)\tAcc@5  81.05 ( 80.38)\n",
      "Epoch: [0][ 950/1252]\tTime  6.409 ( 6.538)\tData  5.842 ( 5.965)\tLoss 1.6829e+00 (1.9345e+00)\tAcc@1  58.50 ( 55.95)\tAcc@5  84.77 ( 80.49)\n",
      "Epoch: [0][1000/1252]\tTime  6.566 ( 6.535)\tData  5.998 ( 5.963)\tLoss 1.8022e+00 (1.9264e+00)\tAcc@1  58.40 ( 56.05)\tAcc@5  81.35 ( 80.59)\n",
      "Epoch: [0][1050/1252]\tTime  6.381 ( 6.534)\tData  5.812 ( 5.962)\tLoss 1.7673e+00 (1.9193e+00)\tAcc@1  58.11 ( 56.12)\tAcc@5  82.23 ( 80.67)\n",
      "Epoch: [0][1100/1252]\tTime  6.533 ( 6.532)\tData  5.965 ( 5.960)\tLoss 1.6934e+00 (1.9131e+00)\tAcc@1  58.69 ( 56.19)\tAcc@5  83.50 ( 80.74)\n",
      "Epoch: [0][1150/1252]\tTime  6.578 ( 6.529)\tData  6.009 ( 5.957)\tLoss 1.8506e+00 (1.9078e+00)\tAcc@1  57.81 ( 56.24)\tAcc@5  80.66 ( 80.80)\n",
      "Epoch: [0][1200/1252]\tTime  6.544 ( 6.527)\tData  5.976 ( 5.956)\tLoss 1.7124e+00 (1.9029e+00)\tAcc@1  59.67 ( 56.29)\tAcc@5  83.59 ( 80.85)\n",
      "Epoch: [0][1250/1252]\tTime  6.141 ( 6.528)\tData  5.572 ( 5.957)\tLoss 1.7352e+00 (1.8989e+00)\tAcc@1  59.67 ( 56.34)\tAcc@5  83.01 ( 80.89)\n",
      "Test: [ 0/49]\tTime  9.864 ( 9.864)\tLoss 1.6612e+00 (1.6612e+00)\tAcc@1  62.99 ( 62.99)\tAcc@5  83.79 ( 83.79)\n",
      " * Acc@1 43.708 Acc@5 70.724\n",
      "lr: [0.05000500000000001]\n",
      "Epoch: [1][   0/1252]\tTime  7.486 ( 7.486)\tData  6.915 ( 6.915)\tLoss 1.7129e+00 (1.7129e+00)\tAcc@1  59.28 ( 59.28)\tAcc@5  83.89 ( 83.89)\n",
      "Epoch: [1][  50/1252]\tTime  6.250 ( 6.346)\tData  5.683 ( 5.778)\tLoss 1.4578e+00 (1.5525e+00)\tAcc@1  64.16 ( 63.01)\tAcc@5  86.91 ( 85.63)\n",
      "Epoch: [1][ 100/1252]\tTime  6.221 ( 6.363)\tData  5.654 ( 5.795)\tLoss 1.3991e+00 (1.4931e+00)\tAcc@1  64.65 ( 64.34)\tAcc@5  87.79 ( 86.40)\n",
      "Epoch: [1][ 150/1252]\tTime  6.414 ( 6.393)\tData  5.846 ( 5.825)\tLoss 1.4022e+00 (1.4692e+00)\tAcc@1  65.92 ( 64.95)\tAcc@5  87.60 ( 86.72)\n",
      "Epoch: [1][ 200/1252]\tTime  6.534 ( 6.402)\tData  5.965 ( 5.834)\tLoss 1.3845e+00 (1.4552e+00)\tAcc@1  65.04 ( 65.21)\tAcc@5  87.89 ( 86.94)\n",
      "Epoch: [1][ 250/1252]\tTime  6.476 ( 6.425)\tData  5.908 ( 5.857)\tLoss 1.4219e+00 (1.4465e+00)\tAcc@1  66.80 ( 65.34)\tAcc@5  87.01 ( 87.07)\n",
      "Epoch: [1][ 300/1252]\tTime  6.663 ( 6.440)\tData  6.095 ( 5.872)\tLoss 1.3739e+00 (1.4419e+00)\tAcc@1  65.92 ( 65.40)\tAcc@5  87.30 ( 87.13)\n",
      "Epoch: [1][ 350/1252]\tTime  7.115 ( 6.451)\tData  6.547 ( 5.883)\tLoss 1.3652e+00 (1.4367e+00)\tAcc@1  66.89 ( 65.52)\tAcc@5  88.09 ( 87.19)\n",
      "Epoch: [1][ 400/1252]\tTime  6.367 ( 6.458)\tData  5.798 ( 5.890)\tLoss 1.5061e+00 (1.4349e+00)\tAcc@1  65.33 ( 65.53)\tAcc@5  85.45 ( 87.21)\n",
      "Epoch: [1][ 450/1252]\tTime  6.478 ( 6.468)\tData  5.909 ( 5.900)\tLoss 1.4319e+00 (1.4348e+00)\tAcc@1  63.87 ( 65.52)\tAcc@5  87.30 ( 87.20)\n",
      "Epoch: [1][ 500/1252]\tTime  6.556 ( 6.472)\tData  5.987 ( 5.904)\tLoss 1.4038e+00 (1.4342e+00)\tAcc@1  66.41 ( 65.53)\tAcc@5  88.18 ( 87.20)\n",
      "Epoch: [1][ 550/1252]\tTime  6.438 ( 6.477)\tData  5.869 ( 5.909)\tLoss 1.5101e+00 (1.4346e+00)\tAcc@1  64.26 ( 65.53)\tAcc@5  86.13 ( 87.20)\n",
      "Epoch: [1][ 600/1252]\tTime  6.609 ( 6.483)\tData  6.042 ( 5.915)\tLoss 1.4411e+00 (1.4361e+00)\tAcc@1  65.23 ( 65.48)\tAcc@5  87.40 ( 87.18)\n",
      "Epoch: [1][ 650/1252]\tTime  6.423 ( 6.483)\tData  5.856 ( 5.915)\tLoss 1.4731e+00 (1.4387e+00)\tAcc@1  63.57 ( 65.43)\tAcc@5  87.11 ( 87.14)\n",
      "Epoch: [1][ 700/1252]\tTime  6.320 ( 6.485)\tData  5.753 ( 5.917)\tLoss 1.4938e+00 (1.4394e+00)\tAcc@1  63.09 ( 65.40)\tAcc@5  85.84 ( 87.13)\n",
      "Epoch: [1][ 750/1252]\tTime  6.654 ( 6.482)\tData  6.087 ( 5.914)\tLoss 1.4221e+00 (1.4402e+00)\tAcc@1  65.33 ( 65.39)\tAcc@5  88.38 ( 87.11)\n",
      "Epoch: [1][ 800/1252]\tTime  6.343 ( 6.483)\tData  5.776 ( 5.915)\tLoss 1.4661e+00 (1.4417e+00)\tAcc@1  63.18 ( 65.36)\tAcc@5  86.52 ( 87.10)\n",
      "Epoch: [1][ 850/1252]\tTime  6.371 ( 6.486)\tData  5.804 ( 5.918)\tLoss 1.4712e+00 (1.4429e+00)\tAcc@1  64.65 ( 65.33)\tAcc@5  86.33 ( 87.07)\n",
      "Epoch: [1][ 900/1252]\tTime  6.712 ( 6.487)\tData  6.143 ( 5.919)\tLoss 1.4932e+00 (1.4438e+00)\tAcc@1  62.79 ( 65.30)\tAcc@5  86.91 ( 87.07)\n",
      "Epoch: [1][ 950/1252]\tTime  6.324 ( 6.492)\tData  5.756 ( 5.924)\tLoss 1.4973e+00 (1.4445e+00)\tAcc@1  64.55 ( 65.28)\tAcc@5  86.04 ( 87.07)\n",
      "Epoch: [1][1000/1252]\tTime  6.441 ( 6.493)\tData  5.874 ( 5.925)\tLoss 1.4851e+00 (1.4453e+00)\tAcc@1  63.38 ( 65.26)\tAcc@5  87.11 ( 87.06)\n",
      "Epoch: [1][1050/1252]\tTime  6.514 ( 6.495)\tData  5.946 ( 5.927)\tLoss 1.5230e+00 (1.4474e+00)\tAcc@1  64.06 ( 65.22)\tAcc@5  86.04 ( 87.02)\n",
      "Epoch: [1][1100/1252]\tTime  6.687 ( 6.495)\tData  6.120 ( 5.927)\tLoss 1.5142e+00 (1.4494e+00)\tAcc@1  62.60 ( 65.17)\tAcc@5  86.23 ( 86.99)\n",
      "Epoch: [1][1150/1252]\tTime  6.585 ( 6.495)\tData  6.018 ( 5.927)\tLoss 1.3665e+00 (1.4508e+00)\tAcc@1  67.09 ( 65.14)\tAcc@5  87.30 ( 86.97)\n",
      "Epoch: [1][1200/1252]\tTime  6.308 ( 6.497)\tData  5.739 ( 5.929)\tLoss 1.5236e+00 (1.4527e+00)\tAcc@1  63.96 ( 65.10)\tAcc@5  86.62 ( 86.94)\n",
      "Epoch: [1][1250/1252]\tTime  6.450 ( 6.498)\tData  5.881 ( 5.930)\tLoss 1.4815e+00 (1.4547e+00)\tAcc@1  64.45 ( 65.06)\tAcc@5  86.52 ( 86.92)\n",
      "Test: [ 0/49]\tTime  8.055 ( 8.055)\tLoss 1.5585e+00 (1.5585e+00)\tAcc@1  62.30 ( 62.30)\tAcc@5  85.55 ( 85.55)\n",
      " * Acc@1 46.854 Acc@5 72.586\n",
      "lr: [1e-05]\n",
      "CPU times: user 27min 5s, sys: 4min 23s, total: 31min 28s\n",
      "Wall time: 4h 42min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for epoch in range(START_EPOCH, EPOCHS):\n",
    "#    adjust_learning_rate(optimizer, epoch)\n",
    "\n",
    "    # train for one epoch\n",
    "    train(train_loader, model, criterion, optimizer, epoch)\n",
    "\n",
    "    # evaluate on validation set\n",
    "    acc1 = validate(val_loader, model, criterion)\n",
    "\n",
    "    # remember best acc@1 and save checkpoint\n",
    "    is_best = acc1 > best_acc1\n",
    "    best_acc1 = max(acc1, best_acc1)\n",
    "\n",
    "    if RANK == 0:\n",
    "        save_checkpoint({\n",
    "            'epoch': epoch + 1,\n",
    "            'arch': ARCH,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'best_acc1': best_acc1,\n",
    "            'optimizer' : optimizer.state_dict(),\n",
    "        }, is_best)\n",
    "    \n",
    "    scheduler.step()\n",
    "    print('lr: ' + str(scheduler.get_last_lr()))\n",
    "    \n",
    "# close TensorBoard writer\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "017423b4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "45c4cb64",
    "outputId": "996942c0-1c50-4d8f-d0a6-481c3de7200e"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbcedbe4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "11839112304746f9a7fd76784958faa4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e952a4ef79f2406082f01c1ef44be20e",
      "max": 46830571,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e62345a5fe3244e3ad50cee5ff01ae93",
      "value": 46830571
     }
    },
    "2a592d63a5b24791ad351b5c911fac65": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2a86b108d37548eba7e5042a00f6d63a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3ed3d41696734302b0a8c2bb5a9026cc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4205c04d3e5c4244b144861a9263a322",
       "IPY_MODEL_11839112304746f9a7fd76784958faa4",
       "IPY_MODEL_ae70f8cd257b47cc9af26e1dc7c1ec38"
      ],
      "layout": "IPY_MODEL_620dae24fc9e4be0b245c019bfb7f4c5"
     }
    },
    "4205c04d3e5c4244b144861a9263a322": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dee11a91c86e4ca1a05b7cb62af41fee",
      "placeholder": "​",
      "style": "IPY_MODEL_48c5147a2da546af988e4dea6703653a",
      "value": "100%"
     }
    },
    "48c5147a2da546af988e4dea6703653a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "620dae24fc9e4be0b245c019bfb7f4c5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ae70f8cd257b47cc9af26e1dc7c1ec38": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2a86b108d37548eba7e5042a00f6d63a",
      "placeholder": "​",
      "style": "IPY_MODEL_2a592d63a5b24791ad351b5c911fac65",
      "value": " 44.7M/44.7M [00:00&lt;00:00, 59.7MB/s]"
     }
    },
    "dee11a91c86e4ca1a05b7cb62af41fee": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e62345a5fe3244e3ad50cee5ff01ae93": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e952a4ef79f2406082f01c1ef44be20e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
